{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1\n",
    "\n",
    "Take the titanic dataset and using all attributes to predict the class `Survived` (convert age and fare into classes ; exclude names from the attribute list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "% matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "titanic = pd.read_csv('../Data/titanic.csv.zst', index_col='Name')\n",
    "\n",
    "titanic.describe(include='all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we create classes and label them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "titanic['Age Group'] = pd.qcut(x=titanic['Age'], q=4)\n",
    "titanic['Fare Group'] = pd.qcut(x=titanic['Fare'], q=4)\n",
    "\n",
    "for col in ['Sex', 'Age Group', 'Fare Group']:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    titanic[col] = le.fit_transform(titanic[col])\n",
    "\n",
    "titanic.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some preliminary definitions to use later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_features = ['Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Age Group', 'Fare Group']\n",
    "max_depth = len(all_features) + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## (a) Choose Three classifiers and evaluate their performance using all attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'KNN': KNeighborsClassifier(metric='canberra'),\n",
    "    # Note: We use the `canberra` metric, as it has proven to be the best one in the past exercises.\n",
    "    'Na√Øve Bayes': GaussianNB(),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from util import *\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'{model}:')\n",
    "    a, p, r, f = kfold_eval(model, titanic[all_features], titanic['Survived'], 5)\n",
    "    data = {\n",
    "        'Fold': range(1, 6),\n",
    "        'Accuracy': a,\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F1-Score': f,\n",
    "    }\n",
    "\n",
    "    scores = pd.DataFrame(data).set_index('Fold')\n",
    "    display(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (b) Define a feature selection method and use it on all the classifiers;\n",
    "We will be using PCA for this task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pca_eval import *\n",
    "\n",
    "for name, model in models.items():\n",
    "    a, p, r, f1 = pca_eval(model, titanic[all_features], titanic['Survived'], k=5, c=4)\n",
    "\n",
    "    print(f'{name}:')\n",
    "    data = {\n",
    "        'Fold': range(1, 6),\n",
    "        'Accuracy': a,\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F1-Score': f,\n",
    "    }\n",
    "\n",
    "    scores = pd.DataFrame(data).set_index('Fold')\n",
    "    display(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (c) Compare the classifiers and explain the differences observed;\n",
    "\n",
    "PCA is a data reduction technique compressing all features into just a few principal components.\n",
    "\n",
    "The performance seems to be consistently lower though.\n",
    "Further checking/changing code did not shine light on as to why."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
